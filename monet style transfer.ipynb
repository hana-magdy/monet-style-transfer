{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom math import floor\nimport pandas as pd \nimport cv2\nimport matplotlib.gridspec as gridspec\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport random\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam\nfrom numpy.random import randn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-24T15:19:46.256110Z","iopub.execute_input":"2021-09-24T15:19:46.256497Z","iopub.status.idle":"2021-09-24T15:19:46.263172Z","shell.execute_reply.started":"2021-09-24T15:19:46.256464Z","shell.execute_reply":"2021-09-24T15:19:46.262206Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"original = []\n\nfor filename in os.listdir('/kaggle/input/gan-getting-started/monet_jpg'):\n    original.append(np.array(Image.open('/kaggle/input/gan-getting-started/monet_jpg/'+str(filename)).resize((128,128))))\n    #original.append(np.array(Image.open('/kaggle/input/gan-getting-started/monet_jpg/'+str(filename))))\n    \nprint(np.array(original).shape)\noriginal = (np.array(original)- 127.5) / 127.5  #normalize the input images to speed up the training\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:46.268910Z","iopub.execute_input":"2021-09-24T15:19:46.269399Z","iopub.status.idle":"2021-09-24T15:19:47.070623Z","shell.execute_reply.started":"2021-09-24T15:19:46.269371Z","shell.execute_reply":"2021-09-24T15:19:47.069627Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"def Plot(arr):\n    arr = (arr + 1) / 2.0\n    fig, axes = plt.subplots(2, 2)\n    fig.set_size_inches(16,8)\n    count = 0\n    for i in range(2):\n        for j in range(2):\n            c = arr[count].copy()\n            c.resize((256,256))\n            axes[i, j].imshow(arr[count])\n            axes[i, j].axis('off')\n            count += 1\n    plt.tight_layout() \n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:47.072134Z","iopub.execute_input":"2021-09-24T15:19:47.072653Z","iopub.status.idle":"2021-09-24T15:19:47.080001Z","shell.execute_reply.started":"2021-09-24T15:19:47.072613Z","shell.execute_reply":"2021-09-24T15:19:47.079182Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"Plot(original)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:47.081734Z","iopub.execute_input":"2021-09-24T15:19:47.082221Z","iopub.status.idle":"2021-09-24T15:19:47.605176Z","shell.execute_reply.started":"2021-09-24T15:19:47.082182Z","shell.execute_reply":"2021-09-24T15:19:47.603183Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"latent_dim =100\nheight = 128\nwidth = 128\n\nchannels = 3","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:47.606760Z","iopub.execute_input":"2021-09-24T15:19:47.607083Z","iopub.status.idle":"2021-09-24T15:19:47.612204Z","shell.execute_reply.started":"2021-09-24T15:19:47.607042Z","shell.execute_reply":"2021-09-24T15:19:47.611200Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"def Generator():\n  \n    generator_input = keras.Input(shape = (latent_dim,))\n    \n    init= RandomNormal(mean=0.0, stddev=0.02)\n    gamma_init =RandomNormal(mean=1, stddev=0.02)\n    \n    x = layers.Dense(256 * 1 * 1,kernel_initializer=init)(generator_input)\n    x = layers.Reshape((1,1,256))(x)\n    x = layers.LeakyReLU()(x)\n \n \n    #x = layers.Conv2D(32, 3,strides = 2, padding='same')(x) #stride b 2 to downsample instead of max pooling.\n    #x = layers.LeakyReLU()(x)\n\n    #x = layers.Conv2D(64, 3,strides = 2, padding='same')(x)\n    #x = layers.LeakyReLU()(x)\n  \n  \n    x = layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x) #stride 2 with covTranspose to upsample.\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)   \n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x)\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x)\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x)\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x)\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x)\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',kernel_initializer=init)(x)\n    x = layers.BatchNormalization(gamma_initializer=gamma_init)(x)\n    x = layers.LeakyReLU()(x)\n    \n  \n  \n \n    x = layers.Conv2DTranspose(channels, 3, activation = 'tanh', padding = 'same')(x)  # tanh to get values between 1 and -1 same as monet images\n\n    generator = keras.models.Model(generator_input, x)\n\n    generator.summary()\n\n    return generator","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:47.614606Z","iopub.execute_input":"2021-09-24T15:19:47.614965Z","iopub.status.idle":"2021-09-24T15:19:47.655330Z","shell.execute_reply.started":"2021-09-24T15:19:47.614910Z","shell.execute_reply":"2021-09-24T15:19:47.654334Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"def Discrimnator():\n    discriminator_input = layers.Input(shape = (height, width, channels))\n    init= RandomNormal(mean=0.0, stddev=0.02)\n    \n    x = layers.Conv2D(64, 4,kernel_initializer=init)(discriminator_input)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2D(128, 4, strides = 2,kernel_initializer=init)(x)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU(0.2)(x)\n  \n    x = layers.Conv2D(128, 4, strides = 2,kernel_initializer=init)(x)\n    #x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n  \n    x = layers.Flatten()(x)\n  \n    x = layers.Dense(1, activation = 'sigmoid')(x)\n  \n    discriminator = keras.models.Model(discriminator_input, x)\n    discriminator.summary()\n\n    return discriminator\n","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:47.656780Z","iopub.execute_input":"2021-09-24T15:19:47.661910Z","iopub.status.idle":"2021-09-24T15:19:47.677068Z","shell.execute_reply.started":"2021-09-24T15:19:47.661867Z","shell.execute_reply":"2021-09-24T15:19:47.676144Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"generator=Generator()\ndiscriminator=Discrimnator()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:47.678590Z","iopub.execute_input":"2021-09-24T15:19:47.679089Z","iopub.status.idle":"2021-09-24T15:19:48.031124Z","shell.execute_reply.started":"2021-09-24T15:19:47.679042Z","shell.execute_reply":"2021-09-24T15:19:48.030200Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n#generator.compile(optimizer = generator_optimizer, loss = 'categorical_crossentropy')\n\ndiscriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n#discriminator.compile(optimizer = discriminator_optimizer,loss='binary_crossentropy')\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:48.036918Z","iopub.execute_input":"2021-09-24T15:19:48.039744Z","iopub.status.idle":"2021-09-24T15:19:48.047854Z","shell.execute_reply.started":"2021-09-24T15:19:48.037419Z","shell.execute_reply":"2021-09-24T15:19:48.046834Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"def Get_Noise_Batch():\n    random_latent_vectors = randn(latent_dim * batch_size)\n    # update to have the range [-1, 1]\n    random_latent_vectors = -1 + random_latent_vectors * 2\n    random_latent_vectors = random_latent_vectors.reshape((batch_size, latent_dim))\n    \n    return random_latent_vectors","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:48.053391Z","iopub.execute_input":"2021-09-24T15:19:48.053997Z","iopub.status.idle":"2021-09-24T15:19:48.064805Z","shell.execute_reply.started":"2021-09-24T15:19:48.053959Z","shell.execute_reply":"2021-09-24T15:19:48.063450Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"def Get_True_Batch(idx):\n    real_images=original[idx:idx+batch_size]\n    return real_images","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:48.066412Z","iopub.execute_input":"2021-09-24T15:19:48.070085Z","iopub.status.idle":"2021-09-24T15:19:48.075584Z","shell.execute_reply.started":"2021-09-24T15:19:48.070011Z","shell.execute_reply":"2021-09-24T15:19:48.074548Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"def G_loss(fake_output):\n     return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:48.077591Z","iopub.execute_input":"2021-09-24T15:19:48.078918Z","iopub.status.idle":"2021-09-24T15:19:48.086680Z","shell.execute_reply.started":"2021-09-24T15:19:48.078879Z","shell.execute_reply":"2021-09-24T15:19:48.085670Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"def D_loss(real_output,fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    return real_loss+fake_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:48.087955Z","iopub.execute_input":"2021-09-24T15:19:48.089336Z","iopub.status.idle":"2021-09-24T15:19:48.097921Z","shell.execute_reply.started":"2021-09-24T15:19:48.089298Z","shell.execute_reply":"2021-09-24T15:19:48.096903Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"gen_loss_total=[]\ndisc_loss_total=[]","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:48.100746Z","iopub.execute_input":"2021-09-24T15:19:48.101843Z","iopub.status.idle":"2021-09-24T15:19:48.108748Z","shell.execute_reply.started":"2021-09-24T15:19:48.101806Z","shell.execute_reply":"2021-09-24T15:19:48.107764Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"def step(i,idx,batch_size=30):\n    \n\n    noise=Get_Noise_Batch()\n    real=Get_True_Batch(idx)\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        \n        real_output = discriminator(real, training=True)\n        fake_output = discriminator(generated_images, training=True)\n        \n        gen_loss = G_loss(fake_output)\n        disc_loss =D_loss(real_output,fake_output)\n\n        \n \n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))\n    \n    \n    if i%200==0 or i==29999 :\n        print(\"Iteration= \",i,\" results:\")   \n        print('discriminator loss:', disc_loss)\n        print('generator loss:', gen_loss)\n        gen_loss_total.append(gen_loss)\n        disc_loss_total.append(disc_loss)\n      \n        Plot(generated_images.numpy())\n    \n   ","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:24:24.938588Z","iopub.execute_input":"2021-09-24T15:24:24.938942Z","iopub.status.idle":"2021-09-24T15:24:24.946811Z","shell.execute_reply.started":"2021-09-24T15:24:24.938902Z","shell.execute_reply":"2021-09-24T15:24:24.945930Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"iterations = 30000\nbatch_size = 60\nidx = 0\n\nfor i in range(iterations):\n    \n    if idx<300:\n        step(i,idx,batch_size=30)\n    else:\n        idx=0\n        step(i,idx,batch_size=30)\n        \n    idx=idx+batch_size\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:24:28.429077Z","iopub.execute_input":"2021-09-24T15:24:28.429429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(list(range(0, iterations+1,200)),gen_loss_total, list(range(0, iterations+1,200)),disc_loss_total)\nplt.legend(['gen loss','disc loss'])\nplt.xlabel(\"iterations\")\nplt.ylabel(\"loss values\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T15:19:49.813458Z","iopub.status.idle":"2021-09-24T15:19:49.814166Z"},"trusted":true},"execution_count":null,"outputs":[]}]}